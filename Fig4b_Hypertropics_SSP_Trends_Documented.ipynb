{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556a0a39",
   "metadata": {},
   "source": [
    "# Figure 4b: Time Series of Hypertropical Land Area Under Different SSP Scenarios\n",
    "\n",
    "This notebook analyzes how the area of hypertropical landâ€”defined as warm (temperature >24 degree celsius) and wet regions (precipitation >1300 mm/yr) in the 99th percentile of global temperature and precipitationâ€”changes under three different Shared Socioeconomic Pathways (SSPs): SSP1-2.6, SSP3-7.0, and SSP5-8.5.\n",
    "\n",
    "It performs the following steps:\n",
    "- Loads historical and future temperature and precipitation data for multiple models.\n",
    "- Identifies extreme warm and wet conditions based on the 99th percentile of land area in historical data and additional precipitation and temperature boundaries for identifying hypertropical regions.\n",
    "- Calculates yearly land fraction meeting those conditions across historical and future periods.\n",
    "- Compares trends across SSP scenarios.\n",
    "\n",
    "**Dependencies:**\n",
    "- `numpy`, `matplotlib`, `xarray`, `rioxarray`, `seaborn`, `pandas`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08c614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91981b",
   "metadata": {},
   "source": [
    "## 1. Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325a9fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC\n",
      "BCC\n",
      "NOAA-GFDL\n",
      "MRI\n",
      "NCC\n",
      "MPI-M\n",
      "CAMS\n",
      "NASA-GISS\n",
      "NCAR\n",
      "CNRM-CERFACS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# historical\n",
    "models_sources_h = [\n",
    "    ('MIROC', 'MIROC-ES2L'),\n",
    "    ('BCC', 'BCC-CSM2-MR'),\n",
    "    ('NOAA-GFDL', 'GFDL-ESM4'),\n",
    "    ('MRI', 'MRI-ESM2-0'),\n",
    "#     ('NCC', 'NorCPM1'),\n",
    "    ('NCC', 'NorESM2-LM'),\n",
    "    ('MPI-M', 'MPI-ESM1-2-LR'), #same as future model\n",
    "#     ('MPI-M', 'MPI-ESM1-2-HR'),\n",
    "    ('CAMS', 'CAMS-CSM1-0'),\n",
    "    ('NASA-GISS', 'GISS-E2-1-G'),\n",
    "    ('NCAR', 'CESM2-WACCM'),\n",
    "    ('CNRM-CERFACS', 'CNRM-CM6-1')]\n",
    "\n",
    "base_path = '/Users/yanlei/Documents/PhD/postdoc_2A/Jeff_Nature/Figure4_CMIP6_datasets/'\n",
    "biome_filepath = '/Users/yanlei/Documents/PhD/postdoc_2A/Jeff_Nature/biome/biomes_data.py'\n",
    "tas_data_list_h = []\n",
    "pr_data_list_h = []\n",
    "\n",
    "# Looping from model 0 to 9\n",
    "for i in range(10):\n",
    "    # Retrieve model short and full names from models_sources\n",
    "    model_short, model_full = models_sources_h[i]\n",
    "    print(model_short)\n",
    "\n",
    "    # Construct the file paths\n",
    "    tas_data= xr.open_dataset(f'{base_path}historical/tas/historical_tas_monthly_1840_2015_{model_short}_{model_full}.nc')\n",
    "    pr_data = xr.open_dataset(f'{base_path}historical/pr/historical_pr_monthly_1840_2015_{model_short}_{model_full}.nc')\n",
    "    mask_data = xr.open_dataset(f'{base_path}sftlf/sftlf_{model_short}_{model_full}.nc')\n",
    "\n",
    "    # Create land mask (considering land points where land fraction is greater than 0%\n",
    "#     landmask = mask_data['sftlf'][0] > 0\n",
    "    landmask = mask_data['sftlf'] > 0\n",
    "\n",
    "    # Apply the land mask to the temperature and precipitation data and convert the unit\n",
    "    tas_data_land = tas_data[\"tas\"].where(landmask, drop=True) - 273.15\n",
    "    pr_data_land = pr_data[\"pr\"].where(landmask, drop=True)* 86400 * 365.25\n",
    "\n",
    "    # Append the land-specific data to respective lists\n",
    "    tas_data_list_h.append(tas_data_land)\n",
    "    pr_data_list_h.append(pr_data_land)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6653e3e",
   "metadata": {},
   "source": [
    "## 2. Load Climate Data and Plot SSP Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3f395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC\n",
      "BCC\n",
      "NOAA-GFDL\n",
      "MRI\n",
      "NCC\n",
      "MPI-M\n",
      "CAMS\n",
      "NASA-GISS\n",
      "NCAR\n",
      "CNRM-CERFACS\n"
     ]
    }
   ],
   "source": [
    "# SSP 126\n",
    "\n",
    "models_sources_f = [\n",
    "    ('MIROC', 'MIROC-ES2L'),\n",
    "    ('BCC', 'BCC-CSM2-MR'),\n",
    "    ('NOAA-GFDL', 'GFDL-ESM4'),\n",
    "    ('MRI', 'MRI-ESM2-0'),\n",
    "    ('NCC', 'NorESM2-LM'), \n",
    "    ('MPI-M', 'MPI-ESM1-2-LR'), \n",
    "    ('CAMS', 'CAMS-CSM1-0'),\n",
    "    ('NASA-GISS', 'GISS-E2-1-G'),\n",
    "    ('NCAR', 'CESM2-WACCM'),\n",
    "    ('CNRM-CERFACS', 'CNRM-CM6-1')\n",
    "]\n",
    "\n",
    "\n",
    "# Future\n",
    "base_path = '/Users/yanlei/Documents/PhD/postdoc_2A/Jeff_Nature/Figure4_CMIP6_datasets/'\n",
    "biome_filepath = '/Users/yanlei/Documents/PhD/postdoc_2A/Jeff_Nature/biome/biomes_data.py'\n",
    "tas_data_list_f_126 = []\n",
    "pr_data_list_f_126 = []\n",
    "\n",
    "\n",
    "# Looping from model 0 to 9\n",
    "for i in range(10):\n",
    "    # Retrieve model short and full names from models_sources\n",
    "    model_short, model_full = models_sources_f[i]\n",
    "    print(model_short)\n",
    "\n",
    "    # Construct file paths for temperature, precipitation, and mask data\n",
    "    tas_data = xr.open_dataset(f'{base_path}ssp126/tas/ssp126_tas_monthly_2015_2100_{model_short}_{model_full}.nc')\n",
    "    pr_data = xr.open_dataset(f'{base_path}ssp126/pr/ssp126_pr_monthly_2015_2100_{model_short}_{model_full}.nc')\n",
    "    mask_data = xr.open_dataset(f'{base_path}sftlf/sftlf_{model_short}_{model_full}.nc')\n",
    "\n",
    "    # Create land mask (considering land points where land fraction is greater than 50%)\n",
    "#     landmask = mask_data['sftlf'][0] > 0\n",
    "    landmask = mask_data['sftlf'] > 0\n",
    "\n",
    "    # Apply the land mask to the temperature and precipitation data\n",
    "    tas_data_land = tas_data[\"tas\"].where(landmask, drop=True)  - 273.15\n",
    "    pr_data_land = pr_data[\"pr\"].where(landmask, drop=True)* 86400 * 365.25\n",
    "\n",
    "    # Append the land-specific data to respective lists\n",
    "    tas_data_list_f_126.append(tas_data_land)\n",
    "    pr_data_list_f_126.append(pr_data_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfb636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC\n",
      "BCC\n"
     ]
    }
   ],
   "source": [
    "# SSP 370\n",
    "\n",
    "\n",
    "# Future\n",
    "tas_data_list_f_370 = []\n",
    "pr_data_list_f_370 = []\n",
    "\n",
    "\n",
    "# Looping from model 0 to 9\n",
    "for i in range(10):\n",
    "    # Retrieve model short and full names from models_sources\n",
    "    model_short, model_full = models_sources_f[i]\n",
    "    print(model_short)\n",
    "\n",
    "    # Construct file paths for temperature, precipitation, and mask data\n",
    "    tas_data = xr.open_dataset(f'{base_path}ssp370/tas/ssp370_tas_monthly_2015_2100_{model_short}_{model_full}.nc')\n",
    "    pr_data = xr.open_dataset(f'{base_path}ssp370/pr/ssp370_pr_monthly_2015_2100_{model_short}_{model_full}.nc')\n",
    "    mask_data = xr.open_dataset(f'{base_path}sftlf/sftlf_{model_short}_{model_full}.nc')\n",
    "\n",
    "    # Create land mask (considering land points where land fraction is greater than 50%)\n",
    "#     landmask = mask_data['sftlf'][0] > 0\n",
    "    landmask = mask_data['sftlf'] > 0\n",
    "\n",
    "    # Apply the land mask to the temperature and precipitation data\n",
    "    tas_data_land = tas_data[\"tas\"].where(landmask, drop=True)  - 273.15\n",
    "    pr_data_land = pr_data[\"pr\"].where(landmask, drop=True)* 86400 * 365.25\n",
    "\n",
    "    # Append the land-specific data to respective lists\n",
    "    tas_data_list_f_370.append(tas_data_land)\n",
    "    pr_data_list_f_370.append(pr_data_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a84173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP 585\n",
    "\n",
    "tas_data_list_f_585 = []\n",
    "pr_data_list_f_585 = []\n",
    "\n",
    "\n",
    "# Looping from model 0 to 9\n",
    "for i in range(10):\n",
    "    # Retrieve model short and full names from models_sources\n",
    "    model_short, model_full = models_sources_f[i]\n",
    "    print(model_short)\n",
    "\n",
    "    # Construct file paths for temperature, precipitation, and mask data\n",
    "    tas_data = xr.open_dataset(f'{base_path}ssp585/tas/ssp585_tas_monthly_2015_2100_{model_short}_{model_full}.nc')\n",
    "    pr_data = xr.open_dataset(f'{base_path}ssp585/pr/ssp585_pr_monthly_2015_2100_{model_short}_{model_full}.nc')\n",
    "    mask_data = xr.open_dataset(f'{base_path}sftlf/sftlf_{model_short}_{model_full}.nc')\n",
    "\n",
    "    # Create land mask (considering land points where land fraction is greater than 50%)\n",
    "#     landmask = mask_data['sftlf'][0] > 0\n",
    "    landmask = mask_data['sftlf'] > 0\n",
    "\n",
    "    # Apply the land mask to the temperature and precipitation data\n",
    "    tas_data_land = tas_data[\"tas\"].where(landmask, drop=True)  - 273.15\n",
    "    pr_data_land = pr_data[\"pr\"].where(landmask, drop=True)* 86400 * 365.25\n",
    "\n",
    "    # Append the land-specific data to respective lists\n",
    "    tas_data_list_f_585.append(tas_data_land)\n",
    "    pr_data_list_f_585.append(pr_data_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d22b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping from model 0 to 9\n",
    "land_mask_l = []\n",
    "for i in range(10):\n",
    "    # Retrieve model short and full names from models_sources\n",
    "    model_short, model_full = models_sources_f[i]\n",
    "    print(model_short)\n",
    "\n",
    "    # Construct file paths for temperature, precipitation, and mask data\n",
    "    mask_data = xr.open_dataset(f'{base_path}sftlf/sftlf_{model_short}_{model_full}.nc')\n",
    "\n",
    "    # Create land mask (considering land points where land fraction is greater than 50%)\n",
    "    landmask = mask_data['sftlf'] > 0\n",
    "    land_mask_l.append(landmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01d234",
   "metadata": {},
   "source": [
    "## 3. Define hypertropical thresholds and calculate yearly fractions of hypertropical area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # cumulative method-correct\n",
    "def calculate_historical_threshold(tas_data_h, pr_data_h, hist_xedges, hist_yedges, land_area, percentile=0.99):\n",
    "    '''\n",
    "    This function use all historical dataset to identify the bins with extreme precipitation and temperature \n",
    "    conditions that composed of the extreme percentile (1% as example here) of the land\n",
    "    The bins are also warm (T> 20 degree Celcius) and wet (P > 1000 mm/year) at the same time\n",
    "    \n",
    "    '''\n",
    "    tas_flat = tas_data_h.mean(dim=\"time\").values.flatten()\n",
    "    pr_flat = pr_data_h.mean(dim=\"time\").values.flatten()\n",
    "    hist2d_h, xedges, yedges = np.histogram2d(tas_flat, pr_flat, bins=(hist_xedges, hist_yedges), weights=land_area.values.flatten())\n",
    "\n",
    "    # Flatten, sort, and calculate the cumulative sum of the histogram\n",
    "    sorted_indices = np.argsort(hist2d_h.flatten())[::-1]  # Indices of bins sorted by land area\n",
    "    sorted_hist = hist2d_h.flatten()[sorted_indices]\n",
    "    cumsum_hist = np.cumsum(sorted_hist)\n",
    "\n",
    "    # Identify the bins that make up the top percentile\n",
    "    top_percent_bins = sorted_indices[cumsum_hist > (hist2d_h.sum() * percentile)]\n",
    "\n",
    "    # Convert these indices back to 2D indices (temperature, precipitation bin indices)\n",
    "    x_idx, y_idx = np.unravel_index(top_percent_bins, hist2d_h.shape)\n",
    "\n",
    "    # Filter for warm and wet conditions\n",
    "    warm_wet_extreme_bins = [(x, y) for x, y in zip(x_idx, y_idx) if xedges[x] > 24 and yedges[y] > 1300]\n",
    "\n",
    "    return warm_wet_extreme_bins\n",
    "\n",
    "\n",
    "def calculate_yearly_fractions(tas_data, pr_data, hist_xedges, hist_yedges, extreme_bins, land_area, total_land_area):\n",
    "    '''\n",
    "    This function calculate yearly land fraction for historical data and future data that the land fall within \n",
    "    the warm and wet extreme condition bins\n",
    "    '''\n",
    "    \n",
    "    fractions = []\n",
    "    years = np.unique(tas_data.coords['time'].dt.year.values)\n",
    "    \n",
    "    for year in years:\n",
    "        tas_year = tas_data.sel(time=str(year)).mean(dim='time')\n",
    "        pr_year = pr_data.sel(time=str(year)).mean(dim='time')\n",
    "\n",
    "        hist2d, _, _ = np.histogram2d(tas_year.values.flatten(), pr_year.values.flatten(), \n",
    "                                         bins=(hist_xedges, hist_yedges), \n",
    "                                         weights=land_area.values.flatten())\n",
    "\n",
    "        hypertropical_area = sum(hist2d[idx] for idx in np.ndindex(hist2d.shape) if idx in extreme_bins)\n",
    "        \n",
    "        fraction = hypertropical_area / total_land_area\n",
    "        fractions.append(round(fraction.item(),5))\n",
    "\n",
    "    return years, fractions\n",
    "\n",
    "def plot_fraction_for_99th_percentile(historical_tas_data, historical_pr_data, tas_data, pr_data, landmask):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     # Define bin edges based on the range of values\n",
    "    hist_xedges = np.linspace(-40, 50, 100)  # Temperature bin edges\n",
    "    hist_yedges = np.linspace(0, 10000, 100)  # Precipitation bin edges\n",
    "\n",
    "    # Calculate land area and total land area\n",
    "    R = 6371000  # Earth's radius in meters\n",
    "    lat_bounds = np.radians(np.linspace(-90, 90, historical_tas_data.sizes['lat'] + 1))\n",
    "    dlat = np.sin(lat_bounds[1:]) - np.sin(lat_bounds[:-1])\n",
    "    dlon = np.radians(np.diff(historical_tas_data.coords['lon']).mean())\n",
    "    areas = R**2 * dlon * dlat\n",
    "    areas_2d = np.outer(areas, np.ones(historical_tas_data.sizes['lon']))\n",
    "    land_area = xr.DataArray(areas_2d, dims=['lat', 'lon'], coords={'lat': historical_tas_data.coords['lat'], 'lon': historical_tas_data.coords['lon']})\n",
    "    # Apply the land-sea mask to the land area\n",
    "    masked_land_area = land_area.where(landmask,  drop=True) \n",
    "    \n",
    "    # Calculate the total land area by summing over the masked land area\n",
    "    total_land_area = masked_land_area.sum()\n",
    "\n",
    "#     total_land_area = land_area.sum()\n",
    "    \n",
    "    # Calculate the 99th percentile threshold from historical data\n",
    "    extreme_bins = calculate_historical_threshold(historical_tas_data, historical_pr_data, hist_xedges, hist_yedges, land_area, percentile=0.99)\n",
    "    # Calculate fractions for historical and future data\n",
    "\n",
    "    years, fractions  = calculate_yearly_fractions(tas_data, pr_data,  hist_xedges, hist_yedges, extreme_bins, land_area, total_land_area)\n",
    "    \n",
    "    return years, fractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize DataFrames to store results\n",
    "historical_results_df = pd.DataFrame()\n",
    "ssp126_results_df = pd.DataFrame()\n",
    "ssp370_results_df = pd.DataFrame()\n",
    "ssp585_results_df = pd.DataFrame()\n",
    "\n",
    "# Loop over all models\n",
    "for i in range(10):  # Assuming you have 10 models\n",
    "    # Run the function for historical data of the i-th model\n",
    "    historical_years, historical_fractions = plot_fraction_for_99th_percentile(tas_data_list_h[i], pr_data_list_h[i], tas_data_list_h[i], pr_data_list_h[i],land_mask_l[i])\n",
    "    # Store historical results\n",
    "    historical_model_results = pd.DataFrame({\n",
    "        'Year': historical_years,\n",
    "        'Fraction': historical_fractions,\n",
    "        'Model': i\n",
    "    })\n",
    "    historical_results_df = pd.concat([historical_results_df, historical_model_results])\n",
    "    \n",
    "    # Store future results\n",
    "    ssp126_years, ssp126_fractions = plot_fraction_for_99th_percentile(tas_data_list_h[i], pr_data_list_h[i], tas_data_list_f_126[i], pr_data_list_f_126[i],land_mask_l[i])\n",
    "    ssp126_model_results = pd.DataFrame({\n",
    "        'Year': ssp126_years,\n",
    "        'Fraction': ssp126_fractions,\n",
    "        'Model': i\n",
    "    })\n",
    "    ssp126_results_df = pd.concat([ssp126_results_df, ssp126_model_results])\n",
    "    \n",
    "    # Store future results\n",
    "    ssp370_years, ssp370_fractions = plot_fraction_for_99th_percentile(tas_data_list_h[i], pr_data_list_h[i], tas_data_list_f_370[i], pr_data_list_f_370[i],land_mask_l[i])\n",
    "    ssp370_model_results = pd.DataFrame({\n",
    "        'Year': ssp370_years,\n",
    "        'Fraction': ssp370_fractions,\n",
    "        'Model': i\n",
    "    })\n",
    "    ssp370_results_df = pd.concat([ssp370_results_df, ssp370_model_results])\n",
    "    \n",
    "    # Store future results\n",
    "    ssp585_years, ssp585_fractions = plot_fraction_for_99th_percentile(tas_data_list_h[i], pr_data_list_h[i], tas_data_list_f_585[i], pr_data_list_f_585[i],land_mask_l[i])\n",
    "    ssp585_model_results = pd.DataFrame({\n",
    "        'Year': ssp585_years,\n",
    "        'Fraction': ssp585_fractions,\n",
    "        'Model': i\n",
    "    })\n",
    "    ssp585_results_df = pd.concat([ssp585_results_df, ssp585_model_results])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb91aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming historical_results_df and future_results_df are defined and populated as before\n",
    "\n",
    "# Reset the index of the DataFrames\n",
    "historical_results_df = historical_results_df.reset_index(drop=True)\n",
    "ssp126_results_df = ssp126_results_df.reset_index(drop=True)\n",
    "ssp370_results_df = ssp370_results_df.reset_index(drop=True)\n",
    "ssp585_results_df = ssp585_results_df.reset_index(drop=True)\n",
    "\n",
    "# Now plot the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot historical data\n",
    "sns.lineplot(data=historical_results_df, x='Year', y='Fraction', color='blue', ci='sd', label='Historical data')\n",
    "\n",
    "# Plot future data with specified colors\n",
    "sns.lineplot(data=ssp126_results_df, x='Year', y='Fraction', color='orange', ci='sd', label='SSP 126')\n",
    "sns.lineplot(data=ssp370_results_df, x='Year', y='Fraction', color='red', ci='sd', label='SSP 370')\n",
    "sns.lineplot(data=ssp585_results_df, x='Year', y='Fraction', color='purple', ci='sd', label='SSP 585')\n",
    "\n",
    "\n",
    "plt.xlabel('Year', fontsize = 20)\n",
    "plt.ylabel('Earth land in the hypertropics', fontsize = 20)\n",
    "plt.tick_params(axis='x', labelsize=15)  # Adjust x-axis tick label size\n",
    "plt.tick_params(axis='y', labelsize=15)  # Adjust y-axis tick label size\n",
    "plt.legend(loc='upper left', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a1b32",
   "metadata": {},
   "source": [
    "## 4.Make figure ready for final publication using Nature setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc59441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reset the index of the DataFrames\n",
    "historical_results_df = historical_results_df.reset_index(drop=True)\n",
    "ssp126_results_df = ssp126_results_df.reset_index(drop=True)\n",
    "ssp370_results_df = ssp370_results_df.reset_index(drop=True)\n",
    "ssp585_results_df = ssp585_results_df.reset_index(drop=True)\n",
    "\n",
    "# Set Nature-style font and figure settings\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Arial',\n",
    "    'font.size': 7,\n",
    "    'axes.labelsize': 8,\n",
    "    'axes.titlesize': 8,\n",
    "    'xtick.labelsize': 7,\n",
    "    'ytick.labelsize': 7,\n",
    "    'legend.fontsize': 7,\n",
    "    'pdf.fonttype': 42,\n",
    "    'lines.linewidth': 1.0  # thinner lines, consistent with Nature aesthetics\n",
    "})\n",
    "\n",
    "# Create the figure with the same size as Figure 4a\n",
    "fig = plt.figure(figsize=(3.5, 2.6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Plot historical and future scenarios\n",
    "sns.lineplot(data=historical_results_df, x='Year', y='Fraction', color='blue', ci='sd', label='Historical', ax=ax)\n",
    "sns.lineplot(data=ssp126_results_df, x='Year', y='Fraction', color='orange', ci='sd', label='SSP 126', ax=ax)\n",
    "sns.lineplot(data=ssp370_results_df, x='Year', y='Fraction', color='red', ci='sd', label='SSP 370', ax=ax)\n",
    "sns.lineplot(data=ssp585_results_df, x='Year', y='Fraction', color='purple', ci='sd', label='SSP 585', ax=ax)\n",
    "\n",
    "# Axis labels\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Earth land in the hypertropics')\n",
    "\n",
    "# Legend\n",
    "ax.legend(loc='upper left', fontsize=7, frameon=False)\n",
    "\n",
    "# Panel label \"b\"\n",
    "ax.text(-0.12, 1.08, 'b', transform=ax.transAxes,\n",
    "        fontsize=10, fontweight='bold', fontname='Arial', va='top', ha='left')\n",
    "\n",
    "# Final layout and save\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"Figure4b_HistoricalFutureTrend.jpg\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98233897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
